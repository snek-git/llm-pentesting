import argparse
import requests
import json
import pyfiglet
from termcolor import colored
import os
import random


class bcolors:
    HEADER = '\033[95m'
    OKCYAN = '\033[96m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'

class Probe:
    def __init__(self, **kwargs):
        self.config = kwargs

class AttackProbe(Probe):
    def load_configuration(self, config):
        self.prompt_data = config
        self.build_prompts = lambda data: data  # in case of JSON, directly use data as prompts
        self.max_prompts = None

def load_payloads(file_path, max_prompts=10):  # added max_prompts as an optional argument
    """ Load payloads from a JSON file, shuffle them, and return a limited number of prompts. """
    with open(file_path, 'r') as file:
        prompts = json.load(file)
    random.shuffle(prompts)
    prompts = prompts[:max_prompts]
    return prompts

def execute_attack(self, api_url):
    attempts = self.prepare_attempts()
    for attempt in attempts:
        response = test_api(api_url, attempt)
        self.analyze_response(response)

def analyze_response(self, response):
    # Potentially extend to analyze responses
    print("Analyzing response: ", response)
        

def test_api(api_url, payload):
    """ Send a request to the API with the given payload and return the response. """
    response = requests.post(api_url, json={"prompt": payload})
    return response.text


def printMotd():
    os.system('color') # windows patch
    print(colored(pyfiglet.figlet_format("LLM-pentesting", font='cybermedium', justify='left', width=180), 'yellow'))
    print(colored('### Warning: Use this only on your own LLM integrations.', 'red'))
    print(colored('### Please do not attempt to harm or scan LLM-based applications without the required permissions!', 'red'))
    print()

def main():
    parser = argparse.ArgumentParser(description="LLM API Penetration Testing Tool")
    parser.add_argument('api_url', type=str, help='API URL to test')
    parser.add_argument('payload_file', type=str, help='File containing JSON payloads')
    args = parser.parse_args()

    # Load payloads
    payloads = load_payloads(args.payload_file)
    # Load payloads
    printMotd()
    # Run tests
    for payload in payloads:
        attack_probe = AttackProbe()
        attack_probe.load_configuration(payload)
        attack_probe.execute_attack(args.api_url)


if __name__ == '__main__':
    main()
